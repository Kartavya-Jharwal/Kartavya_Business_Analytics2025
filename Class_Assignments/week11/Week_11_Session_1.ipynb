{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kartavya-Jharwal/Kartavya_Business_Analytics2025/blob/main/Class_Assignments/week11/Week_11_Session_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iG45xBIwGMfh"
      },
      "source": [
        "# Week 11 Session 1: Multiple Regression Analysis\n",
        "\n",
        "## Problem Statement\n",
        "\n",
        "A distributor of frozen dessert pies wants to evaluate factors thought to influence demand.\n",
        "\n",
        "**Variables:**\n",
        "- **Dependent Variable:** Pie Sales (units per week)\n",
        "- **Independent Variables:** Advertising ($100)\n",
        "\n",
        "## Hypotheses\n",
        "\n",
        "**Null Hypothesis (H₀):** β₁ = β₂ = 0 (No significant relationship between independent variables and pie sales)\n",
        "\n",
        "**Alternative Hypothesis (H₁):** At least one βᵢ ≠ 0 (At least one independent variable has a significant relationship with pie sales)\n",
        "\n",
        "**Significance Level:** α = 0.05  \n",
        "**Confidence Interval:** 95%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGjOyCT5Gyh7"
      },
      "source": [
        "## Analysis Plan\n",
        "\n",
        "1. **Data Loading and Inspection**\n",
        "2. **Exploratory Data Analysis (EDA)** - Visualizations and descriptive statistics\n",
        "3. **Correlation Analysis** - Correlation matrix and heatmap\n",
        "4. **Multicollinearity Check** - VIF (Variance Inflation Factor) analysis\n",
        "5. **Multiple Regression Model**\n",
        "6. **F-test** - Overall model significance\n",
        "7. **T-tests** - Individual predictor significance"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Required Libraries"
      ],
      "metadata": {
        "id": "wiohkMFoFs8Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnHmu71iMr4y"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set visualization style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (10, 6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEpam_csG2rk"
      },
      "source": [
        "## Step 1: Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7a_z9coGMq4"
      },
      "outputs": [],
      "source": [
        "# Load the data (update the file path as needed)\n",
        "# df = pd.read_excel('your_file.xlsx')\n",
        "\n",
        "# For demonstration, creating sample data based on the problem\n",
        "# Replace this with actual file loading\n",
        "data = {\n",
        "    'Pie_Sales': [350, 460, 550, 420, 610, 700, 480, 390, 580, 650, 520, 440, 600, 720, 530],\n",
        "    'Advertising': [2.5, 3.0, 4.0, 2.8, 4.5, 5.2, 3.2, 2.6, 4.2, 4.8, 3.8, 3.0, 4.4, 5.5, 3.9]\n",
        "}\n",
        "\n",
        "# df = pd.read_excel('your_file.xlsx')  # Update with your actual file path\n",
        "df = pd.DataFrame(data)  # Uncomment this line if using sample data\n",
        "\n",
        "print(\"Data loaded successfully!\")\n",
        "print(f\"Shape: {df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5D91LfimGDs8"
      },
      "outputs": [],
      "source": [
        "## Step 2: Initial Data Inspection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytkizLMPGL1C"
      },
      "outputs": [],
      "source": [
        "# Display first few rows\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(df.head())\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
        "\n",
        "# Display basic information\n",
        "print(\"Dataset Information:\")\n",
        "print(df.info())\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
        "\n",
        "# Display descriptive statistics\n",
        "print(\"Descriptive Statistics:\")\n",
        "print(df.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8uGbT3lGKVd"
      },
      "outputs": [],
      "source": [
        "## Step 3: Exploratory Data Analysis (EDA)\n",
        "\n",
        "### Scatterplots: Independent Variables vs Dependent Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIAyA3UzMr42"
      },
      "outputs": [],
      "source": [
        "# Get independent and dependent variable names\n",
        "dependent_var = 'Pie_Sales'\n",
        "independent_vars = [col for col in df.columns if col != dependent_var]\n",
        "\n",
        "# Create scatterplots for each independent variable against the dependent variable\n",
        "n_vars = len(independent_vars)\n",
        "fig, axes = plt.subplots(1, n_vars, figsize=(8*n_vars, 6))\n",
        "\n",
        "# Handle single variable case\n",
        "if n_vars == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for i, var in enumerate(independent_vars):\n",
        "    axes[i].scatter(df[var], df[dependent_var], alpha=0.6, s=100, edgecolors='black')\n",
        "    axes[i].set_xlabel(f'{var}', fontsize=12, fontweight='bold')\n",
        "    axes[i].set_ylabel(f'{dependent_var}', fontsize=12, fontweight='bold')\n",
        "    axes[i].set_title(f'{dependent_var} vs {var}', fontsize=14, fontweight='bold')\n",
        "    axes[i].grid(True, alpha=0.3)\n",
        "\n",
        "    # Set axes to start at 0\n",
        "    axes[i].set_xlim(left=0)\n",
        "    axes[i].set_ylim(bottom=0)\n",
        "\n",
        "    # Add trend line\n",
        "    z = np.polyfit(df[var], df[dependent_var], 1)\n",
        "    p = np.poly1d(z)\n",
        "    axes[i].plot(df[var], p(df[var]), \"r--\", alpha=0.8, linewidth=2, label='Trend line')\n",
        "    axes[i].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkL4sBANMr42"
      },
      "outputs": [],
      "source": [
        "# Create heatmap for correlation matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix,\n",
        "            annot=True,\n",
        "            cmap='coolwarm',\n",
        "            center=0,\n",
        "            square=True,\n",
        "            linewidths=1,\n",
        "            cbar_kws={\"shrink\": 0.8},\n",
        "            fmt='.3f',\n",
        "            vmin=-1, vmax=1)\n",
        "plt.title('Correlation Heatmap', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nInterpretation:\")\n",
        "print(\"- Values close to 1 indicate strong positive correlation\")\n",
        "print(\"- Values close to -1 indicate strong negative correlation\")\n",
        "print(\"- Values close to 0 indicate weak or no correlation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiRu8jLgMr42"
      },
      "outputs": [],
      "source": [
        "# Calculate VIF for each independent variable\n",
        "# Get only independent variables\n",
        "X = df[independent_vars]\n",
        "\n",
        "# Add constant for VIF calculation\n",
        "X_with_const = sm.add_constant(X)\n",
        "\n",
        "# Calculate VIF\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Variable\"] = X_with_const.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X_with_const.values, i)\n",
        "                   for i in range(X_with_const.shape[1])]\n",
        "\n",
        "print(\"Variance Inflation Factor (VIF) Analysis:\")\n",
        "print(\"=\"*60)\n",
        "print(vif_data)\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
        "\n",
        "# Interpretation\n",
        "print(\"Interpretation:\")\n",
        "for idx, row in vif_data.iterrows():\n",
        "    if row['Variable'] != 'const':\n",
        "        if row['VIF'] < 5:\n",
        "            status = \"✓ Low multicollinearity (Good)\"\n",
        "        elif row['VIF'] < 10:\n",
        "            status = \"⚠ Moderate multicollinearity (Caution)\"\n",
        "        else:\n",
        "            status = \"✗ High multicollinearity (Problematic)\"\n",
        "        print(f\"  {row['Variable']}: VIF = {row['VIF']:.3f} - {status}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xz7PV1loMr43"
      },
      "outputs": [],
      "source": [
        "# T-test results for individual predictors\n",
        "print(\"T-Tests for Individual Predictors:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Create a summary table\n",
        "coef_summary = pd.DataFrame({\n",
        "    'Variable': model.params.index,\n",
        "    'Coefficient': model.params.values,\n",
        "    'Std Error': model.bse.values,\n",
        "    't-statistic': model.tvalues.values,\n",
        "    'P-value': model.pvalues.values,\n",
        "    'CI Lower (95%)': model.conf_int()[0].values,\n",
        "    'CI Upper (95%)': model.conf_int()[1].values\n",
        "})\n",
        "\n",
        "print(coef_summary.to_string(index=False))\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
        "\n",
        "# Interpretation for each variable\n",
        "print(\"Interpretation:\")\n",
        "alpha = 0.05\n",
        "for idx, row in coef_summary.iterrows():\n",
        "    var_name = row['Variable']\n",
        "    if var_name == 'const':\n",
        "        print(f\"\\n{var_name} (Intercept):\")\n",
        "        print(f\"  Value: {row['Coefficient']:.4f}\")\n",
        "        print(f\"  This is the predicted {dependent_var} when all predictors are 0.\")\n",
        "    else:\n",
        "        print(f\"\\n{var_name}:\")\n",
        "        print(f\"  Coefficient: {row['Coefficient']:.4f}\")\n",
        "        print(f\"  T-statistic: {row['t-statistic']:.4f}\")\n",
        "        print(f\"  P-value: {row['P-value']:.6f}\")\n",
        "\n",
        "        if row['P-value'] < alpha:\n",
        "            print(f\"  ✓ P-value ({row['P-value']:.6f}) < α ({alpha})\")\n",
        "            print(f\"  REJECT the null hypothesis\")\n",
        "            print(f\"  Conclusion: {var_name} is statistically SIGNIFICANT\")\n",
        "            if row['Coefficient'] > 0:\n",
        "                print(f\"  For each unit increase in {var_name}, {dependent_var} increases by {abs(row['Coefficient']):.4f} units.\")\n",
        "            else:\n",
        "                print(f\"  For each unit increase in {var_name}, {dependent_var} decreases by {abs(row['Coefficient']):.4f} units.\")\n",
        "        else:\n",
        "            print(f\"  ✗ P-value ({row['P-value']:.6f}) ≥ α ({alpha})\")\n",
        "            print(f\"  FAIL TO REJECT the null hypothesis\")\n",
        "            print(f\"  Conclusion: {var_name} is NOT statistically significant\")\n",
        "\n",
        "        print(f\"  95% Confidence Interval: [{row['CI Lower (95%)']:.4f}, {row['CI Upper (95%)']:.4f}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLANcxKaMr43"
      },
      "outputs": [],
      "source": [
        "# Summary of key findings\n",
        "print(\"=\"*60)\n",
        "print(\"REGRESSION ANALYSIS SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nDependent Variable: {dependent_var}\")\n",
        "print(f\"Independent Variable(s): {', '.join(independent_vars)}\")\n",
        "print(f\"\\nSample Size: {len(df)}\")\n",
        "print(f\"\\nModel Performance:\")\n",
        "print(f\"  R-squared: {model.rsquared:.4f}\")\n",
        "print(f\"  Adjusted R-squared: {model.rsquared_adj:.4f}\")\n",
        "print(f\"  F-statistic: {model.fvalue:.4f}\")\n",
        "print(f\"  F-test p-value: {model.f_pvalue:.6f}\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"HYPOTHESIS TESTING RESULTS (α = 0.05):\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "# Overall model significance\n",
        "if model.f_pvalue < 0.05:\n",
        "    print(\"\\n✓ OVERALL MODEL: SIGNIFICANT\")\n",
        "    print(f\"  The regression model is statistically significant (p = {model.f_pvalue:.6f})\")\n",
        "else:\n",
        "    print(\"\\n✗ OVERALL MODEL: NOT SIGNIFICANT\")\n",
        "    print(f\"  The regression model is not statistically significant (p = {model.f_pvalue:.6f})\")\n",
        "\n",
        "# Individual predictors\n",
        "print(f\"\\nINDIVIDUAL PREDICTORS:\")\n",
        "for var in independent_vars:\n",
        "    p_val = model.pvalues[var]\n",
        "    coef = model.params[var]\n",
        "    if p_val < 0.05:\n",
        "        print(f\"\\n✓ {var}: SIGNIFICANT (p = {p_val:.6f})\")\n",
        "        print(f\"  Coefficient: {coef:.4f}\")\n",
        "        direction = \"increases\" if coef > 0 else \"decreases\"\n",
        "        print(f\"  Interpretation: Each unit increase in {var} {direction} {dependent_var} by {abs(coef):.4f} units\")\n",
        "    else:\n",
        "        print(f\"\\n✗ {var}: NOT SIGNIFICANT (p = {p_val:.6f})\")\n",
        "        print(f\"  Coefficient: {coef:.4f}\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"MULTICOLLINEARITY CHECK:\")\n",
        "print(f\"{'='*60}\")\n",
        "for idx, row in vif_data.iterrows():\n",
        "    if row['Variable'] != 'const':\n",
        "        if row['VIF'] < 5:\n",
        "            print(f\"✓ {row['Variable']}: VIF = {row['VIF']:.3f} (Low multicollinearity)\")\n",
        "        elif row['VIF'] < 10:\n",
        "            print(f\"⚠ {row['Variable']}: VIF = {row['VIF']:.3f} (Moderate multicollinearity)\")\n",
        "        else:\n",
        "            print(f\"✗ {row['Variable']}: VIF = {row['VIF']:.3f} (High multicollinearity)\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"END OF ANALYSIS\")\n",
        "print(f\"{'='*60}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6HhGMf9Mr44"
      },
      "source": [
        "## Summary and Conclusions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Yq6ZspKMr44"
      },
      "outputs": [],
      "source": [
        "# Get residuals and fitted values\n",
        "residuals = model.resid\n",
        "fitted_values = model.fittedvalues\n",
        "\n",
        "# Create diagnostic plots\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# 1. Residuals vs Fitted Values\n",
        "axes[0, 0].scatter(fitted_values, residuals, alpha=0.6, edgecolors='black')\n",
        "axes[0, 0].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
        "axes[0, 0].set_xlabel('Fitted Values', fontsize=12, fontweight='bold')\n",
        "axes[0, 0].set_ylabel('Residuals', fontsize=12, fontweight='bold')\n",
        "axes[0, 0].set_title('Residuals vs Fitted Values', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Q-Q Plot (Normal Probability Plot)\n",
        "from scipy import stats\n",
        "stats.probplot(residuals, dist=\"norm\", plot=axes[0, 1])\n",
        "axes[0, 1].set_title('Q-Q Plot (Normal Probability Plot)', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Scale-Location Plot (Spread-Location Plot)\n",
        "standardized_residuals = (residuals - residuals.mean()) / residuals.std()\n",
        "axes[1, 0].scatter(fitted_values, np.sqrt(np.abs(standardized_residuals)), alpha=0.6, edgecolors='black')\n",
        "axes[1, 0].set_xlabel('Fitted Values', fontsize=12, fontweight='bold')\n",
        "axes[1, 0].set_ylabel('√|Standardized Residuals|', fontsize=12, fontweight='bold')\n",
        "axes[1, 0].set_title('Scale-Location Plot', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Histogram of Residuals\n",
        "axes[1, 1].hist(residuals, bins=10, edgecolor='black', alpha=0.7)\n",
        "axes[1, 1].set_xlabel('Residuals', fontsize=12, fontweight='bold')\n",
        "axes[1, 1].set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
        "axes[1, 1].set_title('Histogram of Residuals', fontsize=14, fontweight='bold')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Diagnostic Plot Interpretations:\")\n",
        "print(\"=\"*60)\n",
        "print(\"1. Residuals vs Fitted: Should show random scatter around 0\")\n",
        "print(\"2. Q-Q Plot: Points should follow the diagonal line for normality\")\n",
        "print(\"3. Scale-Location: Should show random scatter (constant variance)\")\n",
        "print(\"4. Histogram: Should approximate a normal distribution\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSpP98CGMr44"
      },
      "source": [
        "## Step 7: Model Diagnostics\n",
        "\n",
        "### Residual Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDXNKVJ2Mr44"
      },
      "source": [
        "### T-Tests for Individual Predictors\n",
        "\n",
        "**Purpose:** Test whether each individual independent variable is statistically significant.\n",
        "\n",
        "**Hypotheses for each predictor:**\n",
        "- **H₀:** βᵢ = 0 (The variable has no effect on the dependent variable)\n",
        "- **H₁:** βᵢ ≠ 0 (The variable has a significant effect on the dependent variable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abIItqIbMr45"
      },
      "outputs": [],
      "source": [
        "# F-test results\n",
        "f_statistic = model.fvalue\n",
        "f_pvalue = model.f_pvalue\n",
        "alpha = 0.05\n",
        "\n",
        "print(\"F-Test for Overall Model Significance:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"F-statistic: {f_statistic:.4f}\")\n",
        "print(f\"P-value: {f_pvalue:.6f}\")\n",
        "print(f\"Significance level (α): {alpha}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Interpretation\n",
        "print(\"\\nInterpretation:\")\n",
        "if f_pvalue < alpha:\n",
        "    print(f\"✓ P-value ({f_pvalue:.6f}) < α ({alpha})\")\n",
        "    print(\"  REJECT the null hypothesis\")\n",
        "    print(\"  Conclusion: The overall regression model is statistically significant.\")\n",
        "    print(\"  At least one independent variable has a significant relationship with the dependent variable.\")\n",
        "else:\n",
        "    print(f\"✗ P-value ({f_pvalue:.6f}) ≥ α ({alpha})\")\n",
        "    print(\"  FAIL TO REJECT the null hypothesis\")\n",
        "    print(\"  Conclusion: The overall regression model is NOT statistically significant.\")\n",
        "\n",
        "print(f\"\\nR-squared: {model.rsquared:.4f}\")\n",
        "print(f\"Adjusted R-squared: {model.rsquared_adj:.4f}\")\n",
        "print(f\"This means {model.rsquared*100:.2f}% of the variance in {dependent_var} is explained by the model.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkLUmuAFMr45"
      },
      "source": [
        "### F-Test for Overall Model Significance\n",
        "\n",
        "**Purpose:** Test whether the overall regression model is statistically significant.\n",
        "\n",
        "**Hypotheses:**\n",
        "- **H₀:** β₁ = β₂ = ... = 0 (The model has no explanatory power)\n",
        "- **H₁:** At least one βᵢ ≠ 0 (The model has explanatory power)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpgfIUAuMr45"
      },
      "outputs": [],
      "source": [
        "# Prepare the data for regression\n",
        "X = df[independent_vars]\n",
        "y = df[dependent_var]\n",
        "\n",
        "# Add constant (intercept) to the model\n",
        "X_with_const = sm.add_constant(X)\n",
        "\n",
        "# Fit the regression model\n",
        "model = sm.OLS(y, X_with_const).fit()\n",
        "\n",
        "# Display the regression results\n",
        "print(model.summary())\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_v0H5OEEMr45"
      },
      "source": [
        "## Step 6: Multiple Regression Analysis\n",
        "\n",
        "### Building the Regression Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2PR3ATnMr45"
      },
      "source": [
        "## Step 5: Multicollinearity Check - VIF Analysis\n",
        "\n",
        "**Variance Inflation Factor (VIF)** measures how much the variance of a regression coefficient is inflated due to multicollinearity.\n",
        "\n",
        "**Interpretation:**\n",
        "- VIF = 1: No correlation\n",
        "- VIF < 5: Low multicollinearity (acceptable)\n",
        "- VIF 5-10: Moderate multicollinearity (caution)\n",
        "- VIF > 10: High multicollinearity (problematic)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-hOYpHBMr46"
      },
      "source": [
        "### Correlation Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfzs_97GMr46"
      },
      "outputs": [],
      "source": [
        "# Calculate correlation matrix\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "print(\"Correlation Matrix:\")\n",
        "print(correlation_matrix)\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKUkEhvOMr46"
      },
      "source": [
        "## Step 4: Correlation Analysis\n",
        "\n",
        "### Correlation Matrix"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}