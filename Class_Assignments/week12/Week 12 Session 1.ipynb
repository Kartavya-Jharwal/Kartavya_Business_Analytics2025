{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install & imports — purpose\n",
    "\n",
    "This code cell will install the plotting helper and import plotting, data-manipulation, and ML libraries used in the notebook.\n",
    "\n",
    "Notes:\n",
    "- We use the `%pip` magic to install packages within the notebook environment when needed.\n",
    "- Keep the imports in the code cell and move explanatory comments into markdown to keep code cells clean and focused on runnable statements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XfsqOr01nF7m"
   },
   "outputs": [],
   "source": [
    "%pip install -q qbstyles\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from qbstyles import mpl_style\n",
    "mpl_style(dark=True)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "print('imports completed — ready to load data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JFD5SldTRUrI"
   },
   "source": [
    "# Session 12 — Cardholder Study: Exercise Overview\n",
    "\n",
    "This short exercise walks through a complete statistical workflow using the provided cardholder dataset. Follow the steps below to explore, model, and evaluate a simple logistic regression.\n",
    "\n",
    "**Steps**\n",
    "\n",
    "1. Load libraries\n",
    "2. Load the dataset\n",
    "3. Exploratory Data Analysis (EDA)\n",
    "4. Prepare features and target variables\n",
    "5. Fit a logistic regression model\n",
    "6. Evaluate the model (LLR test, coefficients, confusion matrix, ROC / AUC)\n",
    "7. Display results and create a basic prediction function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D-KQrUQbRUrJ"
   },
   "source": [
    "### Learning objectives\n",
    "\n",
    "- Understand how to prepare data for a basic classification problem.\n",
    "- Build and interpret a logistic regression model.\n",
    "- Perform model-level (LLR) and coefficient-level hypothesis tests.\n",
    "- Evaluate model performance and create a simple prediction function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data (purpose)\n",
    "\n",
    "We will load the cardholder CSV directly from the raw GitHub URL into a pandas DataFrame. After loading we will inspect the shape, data types, first few rows and summary statistics to understand the dataset before modeling.\n",
    "\n",
    "Checklist (manual steps):\n",
    "- Load: df = pd.read_csv(url)\n",
    "- Inspect: df.shape, df.info(), df.head(), df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bvBEjHL_RUrJ"
   },
   "outputs": [],
   "source": [
    "url = (\n",
    "    \"https://raw.githubusercontent.com/Kartavya-Jharwal/Kartavya_Business_Analytics2025/\"\n",
    "    \"main/Class_Assignments/week12/cardholderstudy.csv\"\n",
    ")\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print('shape:', df.shape)\n",
    "\n",
    "df.info()\n",
    "\n",
    "print('\\nhead:')\n",
    "df.head()\n",
    "\n",
    "print('\\nsummary stats:')\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic target / feature split — prefer 'Upgraded' when present\n",
    "# If 'Upgraded' is present use it as the target; otherwise try to find a binary column (0/1) automatically\n",
    "\n",
    "preferred_target = 'Upgraded'\n",
    "if preferred_target in df.columns:\n",
    "    target_col = preferred_target\n",
    "else:\n",
    "    # find binary-like columns (unique values subset of {0,1})\n",
    "    candidate_cols = [col for col in df.columns if set(df[col].dropna().unique()).issubset({0, 1})]\n",
    "    if candidate_cols:\n",
    "        target_col = candidate_cols[0]\n",
    "        print(f\"Auto-selected binary-like target column: '{target_col}'\")\n",
    "    else:\n",
    "        raise RuntimeError(\"No suitable binary target found. Please set `target_col` manually (e.g. 'Upgraded').\")\n",
    "\n",
    "# Create y and X\n",
    "y = df[target_col].copy()\n",
    "X = df.drop(columns=[target_col]).copy()\n",
    "\n",
    "print(f\"Target column: {target_col}\")\n",
    "print('X shape:', X.shape)\n",
    "print('y shape:', y.shape)\n",
    "print('\\nTarget distribution:')\n",
    "print(y.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick EDA — preview, distributions and simple visual checks\n",
    "print('\\nValue counts (target):')\n",
    "print(y.value_counts(dropna=False))\n",
    "\n",
    "print('\\nBasic stats:')\n",
    "print(X.describe())\n",
    "\n",
    "# Small visual checks (histograms)\n",
    "sns.histplot(data=df, x='Purchases', hue=target_col, kde=True)\n",
    "plt.title(f\"Purchases distribution by {target_col}\")\n",
    "plt.show()\n",
    "\n",
    "# Relationship between Extra Cards and target (counts)\n",
    "sns.countplot(data=df, x='Extra Cards', hue=target_col)\n",
    "plt.title(f\"Extra Cards by {target_col} (counts)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cuH9k3nPRUrJ"
   },
   "source": [
    "### Model inference & hypothesis testing\n",
    "\n",
    "- **LLR (Likelihood Ratio) test:** Compare the full model to a null model. Report the p-value and decide whether the model adds predictive power over the null.\n",
    "\n",
    "- **Coefficients & interpretation:** Review estimated coefficients to understand direction (positive/negative) and relative strength of predictors.\n",
    "\n",
    "- **Hypotheses for coefficient tests:**\n",
    "  - H0: beta_i = 0 — predictor i has no relationship with the outcome.\n",
    "  - H1: beta_i != 0 — predictor i is associated with the outcome.\n",
    "\n",
    "- **T-tests / Wald tests:** Use these for individual coefficient significance; report p-values and confidence intervals for each coefficient.\n",
    "\n",
    "- **Sample size:** This exercise uses a small sample (≈30 cases). Interpret p-values cautiously — emphasise effect sizes and confidence intervals as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTlR9-X9RUrK"
   },
   "source": [
    "### Data source\n",
    "\n",
    "Cardholder study CSV (raw):\n",
    "\n",
    "https://raw.githubusercontent.com/Kartavya-Jharwal/Kartavya_Business_Analytics2025/main/Class_Assignments/week12/cardholderstudy.csv\n",
    "\n",
    "Use `pandas.read_csv()` with this URL to load the data directly into the notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare features & target\n",
    "\n",
    "Split the dataset into:\n",
    "\n",
    "- `y` — the dependent variable (target) to predict.\n",
    "- `X` — the predictor variables (features) used by the model.\n",
    "\n",
    "Later: perform a train/test split, handle missing values, and encode/scale features if required before fitting the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit logistic regression (no train/test split)\n",
    "\n",
    "In this step we fit a logistic regression model using the full dataset (no train/test split requested).\n",
    "\n",
    "We will:\n",
    "- Add an intercept term to X and fit a statsmodels Logit model to predict `Upgraded`.\n",
    "- Print the Logit fit summary (coefficients, p-values).\n",
    "- Create predicted probabilities and predicted labels (threshold = 0.5) and attach them to the DataFrame.\n",
    "\n",
    "> Note: Because we are using all data for training and prediction there is a risk of overfitting — this is an instructional demonstration only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare X with constant and fit statsmodels Logit on the full dataset\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Ensure X is ready (if any non-numeric columns exist they'd need encoding here).\n",
    "X_const = sm.add_constant(X)\n",
    "\n",
    "logit_model = sm.Logit(y, X_const)\n",
    "logit_result = logit_model.fit(disp=0)  # disp=0 suppresses iterative output when run\n",
    "\n",
    "# Print the model summary (Logit / GLM-style output)\n",
    "print(logit_result.summary())\n",
    "\n",
    "# Add predictions (probabilities and binary prediction) to df\n",
    "# Predicted probability of Upgraded == 1\n",
    "df['pred_prob'] = logit_result.predict(X_const)\n",
    "# Predicted label using 0.5 threshold\n",
    "df['pred_label'] = (df['pred_prob'] >= 0.5).astype(int)\n",
    "\n",
    "# Show a small sample of predictions and counts\n",
    "print('\\nPrediction counts:')\n",
    "print(df['pred_label'].value_counts())\n",
    "\n",
    "# Optionally show classification metrics on the same data (no train/test split — instructional only)\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print('\\nConfusion matrix on full data:')\n",
    "print(confusion_matrix(y, df['pred_label']))\n",
    "print('\\nClassification report on full data:')\n",
    "print(classification_report(y, df['pred_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn LogisticRegression on full data (no train/test split)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "# If features require scaling, do so — here only 'Purchases' is numeric; Extra Cards is numeric (0/1)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "clf = LogisticRegression(max_iter=200, solver='lbfgs')\n",
    "clf.fit(X_scaled, y)\n",
    "\n",
    "# Coefficients and intercept\n",
    "coef = pd.Series(clf.coef_[0], index=X.columns)\n",
    "intercept = clf.intercept_[0]\n",
    "print('Intercept:', intercept)\n",
    "print('\\nCoefficients:')\n",
    "print(coef)\n",
    "\n",
    "# Predictions on full data\n",
    "pred_prob_sk = clf.predict_proba(X_scaled)[:, 1]\n",
    "df['pred_prob_sk'] = pred_prob_sk\n",
    "df['pred_label_sk'] = (df['pred_prob_sk'] >= 0.5).astype(int)\n",
    "\n",
    "# Metrics on full data (training metrics — no split)\n",
    "print('\\nAccuracy:', accuracy_score(y, df['pred_label_sk']))\n",
    "print('ROC AUC:', roc_auc_score(y, pred_prob_sk))\n",
    "print('\\nConfusion matrix (sklearn)')\n",
    "print(confusion_matrix(y, df['pred_label_sk']))\n",
    "print('\\nClassification report (sklearn)')\n",
    "print(classification_report(y, df['pred_label_sk']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation grid — metrics + confusion matrices (seaborn)\n",
    "\n",
    "Below we'll compute three key classification metrics (accuracy, precision, recall) and show the confusion matrix. The display uses a small grid so you can compare the two model outputs side-by-side.\n",
    "\n",
    "We expect these columns to be available after running previous cells:\n",
    "- `df['pred_label']` (predictions from statsmodels Logit)\n",
    "- `df['pred_label_sk']` (predictions from sklearn LogisticRegression)\n",
    "\n",
    "All metrics below are computed on the full dataset (no train/test split) — this is training-set evaluation only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an evaluation grid showing confusion matrix and (accuracy, precision, recall)\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Specify models to evaluate — only include columns that exist\n",
    "models = {\n",
    "    'statsmodels_logit': 'pred_label',\n",
    "    'sklearn_logreg': 'pred_label_sk'\n",
    "}\n",
    "\n",
    "existing_models = {k: v for k, v in models.items() if v in df.columns}\n",
    "if not existing_models:\n",
    "    raise RuntimeError('No prediction columns found (expected pred_label or pred_label_sk). Run the model cells first.')\n",
    "\n",
    "n_models = len(existing_models)\n",
    "fig, axes = plt.subplots(nrows=n_models, ncols=2, figsize=(10, 4 * n_models))\n",
    "\n",
    "if n_models == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, (name, col) in enumerate(existing_models.items()):\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y, df[col])\n",
    "    ax_cm = axes[i][0] if n_models > 1 else axes[0]\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax_cm)\n",
    "    ax_cm.set_title(f'{name} — confusion matrix')\n",
    "    ax_cm.set_xlabel('Predicted')\n",
    "    ax_cm.set_ylabel('Actual')\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(y, df[col])\n",
    "    prec = precision_score(y, df[col], zero_division=0)\n",
    "    rec = recall_score(y, df[col], zero_division=0)\n",
    "\n",
    "    metrics_df = pd.DataFrame({'metric': ['accuracy', 'precision', 'recall'], 'value': [acc, prec, rec]})\n",
    "    metrics_df = metrics_df.set_index('metric')\n",
    "\n",
    "    ax_m = axes[i][1] if n_models > 1 else axes[1]\n",
    "    sns.heatmap(metrics_df.T, annot=True, fmt='.3f', cmap='Greens', cbar=False, ax=ax_m)\n",
    "    ax_m.set_title(f'{name} — key metrics')\n",
    "    ax_m.set_yticklabels([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
